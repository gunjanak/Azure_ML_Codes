{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "# Load Azure ML Workspace (Assumes config.json is in the same directory)\n",
        "ws = Workspace.from_config()\n",
        "print(\"Azure ML Workspace loaded:\", ws.name)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Azure ML Workspace loaded: azure_ml\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1742716929384
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "\n",
        "pytorch_env = Environment(\"pytorch-env\")\n",
        "pytorch_env.python.conda_dependencies.add_pip_package(\"torch==2.1.0\")\n",
        "pytorch_env.python.conda_dependencies.add_pip_package(\"torchvision==0.16.0\")\n",
        "\n",
        "pytorch_env.register(workspace=ws)\n",
        "print(\"New PyTorch environment created.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "New PyTorch environment created.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1742716929616
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n  warnings.warn(\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1742716934063
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1742716949551
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "import os\n",
        "from azureml.core import Workspace, Experiment, Model, Run\n",
        "\n",
        "run = Run.get_context()"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1742716964510
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"ajayrana/hymenoptera-data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": " 79%|███████▊  | 71.0M/90.2M [00:00<00:00, 73.4MB/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Path to dataset files: /home/azureuser/.cache/kagglehub/datasets/ajayrana/hymenoptera-data/versions/1\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1742716989777
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Downloaded path:\", path)\n",
        "print(\"Files in dataset folder:\", os.listdir(path))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Downloaded path: /home/azureuser/.cache/kagglehub/datasets/ajayrana/hymenoptera-data/versions/1\nFiles in dataset folder: ['hymenoptera_data']\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1742717071257
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "dataset_path = \"./hymenoptera_data\"\n",
        "\n",
        "# Move files if they are already extracted\n",
        "if os.path.isdir(path):\n",
        "    shutil.copytree(path, dataset_path, dirs_exist_ok=True)\n",
        "    print(\"Dataset moved successfully.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Dataset moved successfully.\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1742717129299
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Update path to the correct dataset directory\n",
        "dataset_path = \"./hymenoptera_data/hymenoptera_data/hymenoptera_data\"\n",
        "\n",
        "# Define train and validation directories\n",
        "train_dir = os.path.join(dataset_path, \"train\")\n",
        "val_dir = os.path.join(dataset_path, \"val\")\n",
        "\n",
        "print(\"Train Directory:\", train_dir)\n",
        "print(\"Validation Directory:\", val_dir)\n",
        "\n",
        "# Check if the directories exist\n",
        "assert os.path.isdir(train_dir), \"Train directory not found!\"\n",
        "assert os.path.isdir(val_dir), \"Validation directory not found!\"\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Train Directory: ./hymenoptera_data/hymenoptera_data/hymenoptera_data/train\nValidation Directory: ./hymenoptera_data/hymenoptera_data/hymenoptera_data/val\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1742717270947
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classes in train folder:\", os.listdir(train_dir))\n",
        "print(\"Classes in val folder:\", os.listdir(val_dir))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Classes in train folder: ['ants', 'bees']\nClasses in val folder: ['ants', 'bees']\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1742717284678
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    \"val\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "image_datasets = {\n",
        "    \"train\": datasets.ImageFolder(train_dir, data_transforms[\"train\"]),\n",
        "    \"val\": datasets.ImageFolder(val_dir, data_transforms[\"val\"]),\n",
        "}\n",
        "\n",
        "dataloaders = {\n",
        "    \"train\": torch.utils.data.DataLoader(image_datasets[\"train\"], batch_size=32, shuffle=True),\n",
        "    \"val\": torch.utils.data.DataLoader(image_datasets[\"val\"], batch_size=32, shuffle=False),\n",
        "}\n",
        "\n",
        "class_names = image_datasets[\"train\"].classes\n"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1742717310088
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load VGG16 model\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "# Modify the classifier\n",
        "num_ftrs = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/azureuser/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:02<00:00, 232MB/s]  \n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1742717329912
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    \n",
        "    for phase in [\"train\", \"val\"]:\n",
        "        if phase == \"train\":\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "\n",
        "        running_loss, correct = 0.0, 0\n",
        "        \n",
        "        for inputs, labels in dataloaders[phase]:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with torch.set_grad_enabled(phase == \"train\"):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == \"train\":\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        epoch_loss = running_loss / len(image_datasets[phase])\n",
        "        epoch_acc = correct / len(image_datasets[phase])\n",
        "        print(f\"{phase} Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "print(\"Training complete.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/5\ntrain Loss: 2.8378, Acc: 0.8033\nval Loss: 1.4083, Acc: 0.8954\nEpoch 2/5\ntrain Loss: 1.1733, Acc: 0.8934\nval Loss: 2.6172, Acc: 0.9085\nEpoch 3/5\ntrain Loss: 0.4943, Acc: 0.9713\nval Loss: 2.2651, Acc: 0.9412\nEpoch 4/5\ntrain Loss: 0.3815, Acc: 0.9713\nval Loss: 1.8385, Acc: 0.9412\nEpoch 5/5\ntrain Loss: 0.2831, Acc: 0.9754\nval Loss: 1.6123, Acc: 0.9477\nTraining complete.\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1742720614427
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"vgg16_hymenoptera.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(\"Model saved.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model saved.\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1742720785643
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Model.register(\n",
        "    workspace=ws,\n",
        "    model_path=model_path,\n",
        "    model_name=\"vgg16_hymenoptera\",\n",
        "    description=\"Fine-tuned VGG16 model for hymenoptera classification\",\n",
        ")\n",
        "\n",
        "print(\"Model registered in Azure ML.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Registering model vgg16_hymenoptera\nModel registered in Azure ML.\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1742720829958
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}