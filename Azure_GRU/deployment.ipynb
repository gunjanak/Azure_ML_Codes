{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "env = Environment(name=\"azure_pytorch_env\")\n",
    "env.python.conda_dependencies.add_pip_package(\"torch==2.1.0\")\n",
    "env.python.conda_dependencies.add_pip_package(\"numpy\")\n",
    "env.python.conda_dependencies.add_pip_package(\"scikit-learn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n",
      "/tmp/ipykernel_101937/890583880.py:23: FutureWarning: azureml.core.model:\n",
      "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
      "please refer to respective documentations \n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
      "For more information on migration, see https://aka.ms/acimoemigration \n",
      "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
      "  service = Model.deploy(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2025-04-06 21:57:31+05:45 Creating Container Registry if not exists.\n",
      "2025-04-06 21:57:34+05:45 Use the existing image.\n",
      "2025-04-06 21:57:34+05:45 Generating deployment configuration.\n",
      "2025-04-06 21:57:38+05:45 Submitting deployment to compute.\n",
      "2025-04-06 21:57:43+05:45 Checking the status of deployment pytorch-n-gru-scalar..\n",
      "2025-04-06 22:00:17+05:45 Checking the status of inference endpoint pytorch-n-gru-scalar.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Deployment successful! Scoring URI: http://55648af8-0be3-4b42-bfa7-89419dfbd74d.eastus2.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Model\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "# Connect to Azure ML Workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Load registered model and scaler\n",
    "model = Model(ws, \"pytorch_nn_gru\")\n",
    "scaler = Model(ws, \"adbl_scaler\")\n",
    "\n",
    "\n",
    "# Define inference configuration\n",
    "inference_config = InferenceConfig(\n",
    "    entry_script=\"score.py\",\n",
    "    environment=env\n",
    ")\n",
    "\n",
    "# Define deployment configuration (ACI)\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "# Deploy both the model and scaler\n",
    "service = Model.deploy(\n",
    "    workspace=ws,\n",
    "    name=\"pytorch-n-gru-scalar\",\n",
    "    models=[model, scaler],  # <-- Include both\n",
    "    inference_config=inference_config,\n",
    "    deployment_config=deployment_config\n",
    ")\n",
    "\n",
    "service.wait_for_deployment(show_output=True)\n",
    "\n",
    "# Print Scoring URI\n",
    "print(f\"Deployment successful! Scoring URI: {service.scoring_uri}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /azureml-envs/azureml_51c067e992bfb00fa57ba7a838831dea/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_51c067e992bfb00fa57ba7a838831dea/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_51c067e992bfb00fa57ba7a838831dea/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "2025-04-06T16:15:04,029917213+00:00 - rsyslog/run \n",
      "2025-04-06T16:15:04,034857794+00:00 - gunicorn/run \n",
      "bash: /azureml-envs/azureml_51c067e992bfb00fa57ba7a838831dea/lib/libtinfo.so.6: no version information available (required by bash)\n",
      "2025-04-06T16:15:04,038302235+00:00 | gunicorn/run | \n",
      "2025-04-06T16:15:04,041125968+00:00 | gunicorn/run | ###############################################\n",
      "2025-04-06T16:15:04,043706329+00:00 | gunicorn/run | AzureML Container Runtime Information\n",
      "2025-04-06T16:15:04,045128169+00:00 - nginx/run \n",
      "2025-04-06T16:15:04,046297477+00:00 | gunicorn/run | ###############################################\n",
      "2025-04-06T16:15:04,047935521+00:00 | gunicorn/run | \n",
      "2025-04-06T16:15:04,050935733+00:00 | gunicorn/run | \n",
      "2025-04-06T16:15:04,059312979+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20250121.v1\n",
      "2025-04-06T16:15:04,063058671+00:00 | gunicorn/run | \n",
      "2025-04-06T16:15:04,065922209+00:00 | gunicorn/run | \n",
      "2025-04-06T16:15:04,068953710+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_51c067e992bfb00fa57ba7a838831dea/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
      "2025-04-06T16:15:04,071020373+00:00 | gunicorn/run | PYTHONPATH environment variable: \n",
      "2025-04-06T16:15:04,074240365+00:00 | gunicorn/run | \n",
      "2025-04-06T16:15:06,804329110+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\n",
      "\n",
      "\n",
      "# conda environments:\n",
      "#\n",
      "                     * /azureml-envs/azureml_51c067e992bfb00fa57ba7a838831dea\n",
      "base                   /opt/miniconda\n",
      "\n",
      "2025-04-06T16:15:07,716422072+00:00 | gunicorn/run | \n",
      "2025-04-06T16:15:07,721420528+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n",
      "\n",
      "adal==1.2.7\n",
      "annotated-types==0.7.0\n",
      "argcomplete==3.6.1\n",
      "attrs==25.3.0\n",
      "azure-common==1.1.28\n",
      "azure-core==1.32.0\n",
      "azure-graphrbac==0.61.2\n",
      "azure-identity==1.21.0\n",
      "azure-mgmt-authorization==4.0.0\n",
      "azure-mgmt-containerregistry==10.3.0\n",
      "azure-mgmt-core==1.5.0\n",
      "azure-mgmt-keyvault==10.3.1\n",
      "azure-mgmt-network==28.1.0\n",
      "azure-mgmt-resource==23.3.0\n",
      "azure-mgmt-storage==22.0.0\n",
      "azureml-core==1.59.0.post2\n",
      "azureml-dataprep==5.1.6\n",
      "azureml-dataprep-native==41.0.0\n",
      "azureml-dataprep-rslex==2.22.5\n",
      "azureml-dataset-runtime==1.59.0\n",
      "azureml-defaults==1.59.0\n",
      "azureml-inference-server-http==1.3.4\n",
      "backports.tempfile==1.0\n",
      "backports.weakref==1.0.post1\n",
      "bcrypt==4.3.0\n",
      "blinker==1.8.2\n",
      "cachetools==5.5.2\n",
      "certifi==2025.1.31\n",
      "cffi==1.17.1\n",
      "charset-normalizer==3.4.1\n",
      "click==8.1.8\n",
      "cloudpickle==2.2.1\n",
      "contextlib2==21.6.0\n",
      "cryptography==44.0.2\n",
      "docker==7.1.0\n",
      "filelock==3.16.1\n",
      "Flask==2.3.2\n",
      "Flask-Cors==5.0.0\n",
      "fsspec==2025.3.0\n",
      "fusepy==3.0.1\n",
      "google-api-core==2.24.2\n",
      "google-auth==2.38.0\n",
      "googleapis-common-protos==1.69.2\n",
      "gunicorn==23.0.0\n",
      "humanfriendly==10.0\n",
      "idna==3.10\n",
      "importlib_metadata==8.5.0\n",
      "importlib_resources==6.4.5\n",
      "inference-schema==1.8\n",
      "isodate==0.7.2\n",
      "itsdangerous==2.2.0\n",
      "jeepney==0.9.0\n",
      "Jinja2==3.1.6\n",
      "jmespath==1.0.1\n",
      "joblib==1.4.2\n",
      "jsonpickle==4.0.3\n",
      "jsonschema==4.23.0\n",
      "jsonschema-specifications==2023.12.1\n",
      "knack==0.12.0\n",
      "MarkupSafe==2.1.5\n",
      "mpmath==1.3.0\n",
      "msal==1.32.0\n",
      "msal-extensions==1.3.0\n",
      "msrest==0.7.1\n",
      "msrestazure==0.6.4.post1\n",
      "ndg-httpsclient==0.5.1\n",
      "networkx==3.1\n",
      "numpy==1.23.5\n",
      "nvidia-cublas-cu12==12.1.3.1\n",
      "nvidia-cuda-cupti-cu12==12.1.105\n",
      "nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "nvidia-cuda-runtime-cu12==12.1.105\n",
      "nvidia-cudnn-cu12==8.9.2.26\n",
      "nvidia-cufft-cu12==11.0.2.54\n",
      "nvidia-curand-cu12==10.3.2.106\n",
      "nvidia-cusolver-cu12==11.4.5.107\n",
      "nvidia-cusparse-cu12==12.1.0.106\n",
      "nvidia-nccl-cu12==2.18.1\n",
      "nvidia-nvjitlink-cu12==12.8.93\n",
      "nvidia-nvtx-cu12==12.1.105\n",
      "oauthlib==3.2.2\n",
      "opencensus==0.11.4\n",
      "opencensus-context==0.1.3\n",
      "opencensus-ext-azure==1.1.14\n",
      "packaging==24.2\n",
      "paramiko==3.5.1\n",
      "pathspec==0.12.1\n",
      "pkginfo==1.12.1.2\n",
      "pkgutil_resolve_name==1.3.10\n",
      "proto-plus==1.26.1\n",
      "protobuf==5.29.4\n",
      "psutil==7.0.0\n",
      "pyarrow==17.0.0\n",
      "pyasn1==0.6.1\n",
      "pyasn1_modules==0.4.2\n",
      "pycparser==2.22\n",
      "pydantic==2.9.2\n",
      "pydantic-settings==2.8.1\n",
      "pydantic_core==2.23.4\n",
      "Pygments==2.19.1\n",
      "PyJWT==2.9.0\n",
      "PyNaCl==1.5.0\n",
      "pyOpenSSL==24.3.0\n",
      "PySocks==1.7.1\n",
      "python-dateutil==2.9.0.post0\n",
      "python-dotenv==1.0.1\n",
      "pytz==2025.2\n",
      "PyYAML==6.0.2\n",
      "referencing==0.35.1\n",
      "requests==2.32.3\n",
      "requests-oauthlib==2.0.0\n",
      "rpds-py==0.20.1\n",
      "rsa==4.9\n",
      "scikit-learn==1.3.2\n",
      "scipy==1.10.1\n",
      "SecretStorage==3.3.3\n",
      "six==1.17.0\n",
      "sympy==1.13.3\n",
      "tabulate==0.9.0\n",
      "threadpoolctl==3.5.0\n",
      "torch==2.1.0\n",
      "triton==2.1.0\n",
      "typing_extensions==4.13.0\n",
      "urllib3==2.2.3\n",
      "Werkzeug==3.0.6\n",
      "wrapt==1.16.0\n",
      "zipp==3.20.2\n",
      "\n",
      "2025-04-06T16:15:08,405316962+00:00 | gunicorn/run | \n",
      "2025-04-06T16:15:08,409483651+00:00 | gunicorn/run | Entry script directory: /var/azureml-app/.\n",
      "2025-04-06T16:15:08,411113929+00:00 | gunicorn/run | \n",
      "2025-04-06T16:15:08,412117498+00:00 | gunicorn/run | ###############################################\n",
      "2025-04-06T16:15:08,413230929+00:00 | gunicorn/run | Dynamic Python Package Installation\n",
      "2025-04-06T16:15:08,414296482+00:00 | gunicorn/run | ###############################################\n",
      "2025-04-06T16:15:08,418517948+00:00 | gunicorn/run | \n",
      "2025-04-06T16:15:08,419644523+00:00 | gunicorn/run | Dynamic Python package installation is disabled.\n",
      "2025-04-06T16:15:08,420514678+00:00 | gunicorn/run | \n",
      "2025-04-06T16:15:08,421408483+00:00 | gunicorn/run | ###############################################\n",
      "2025-04-06T16:15:08,422388334+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\n",
      "2025-04-06T16:15:08,423398845+00:00 | gunicorn/run | ###############################################\n",
      "2025-04-06T16:15:08,428552270+00:00 | gunicorn/run | \n",
      "2025-04-06T16:15:09,143246275+00:00 | gunicorn/run | \n",
      "2025-04-06T16:15:09,144504545+00:00 | gunicorn/run | ###############################################\n",
      "2025-04-06T16:15:09,145622886+00:00 | gunicorn/run | AzureML Inference Server\n",
      "2025-04-06T16:15:09,147887758+00:00 | gunicorn/run | ###############################################\n",
      "2025-04-06T16:15:09,148952239+00:00 | gunicorn/run | \n",
      "2025-04-06T16:15:09,153489307+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n",
      "2025-04-06 16:15:09,403 I [73] azmlinfsrv - Loaded logging config from /azureml-envs/azureml_51c067e992bfb00fa57ba7a838831dea/lib/python3.8/site-packages/azureml_inference_server_http/logging.json\n",
      "2025-04-06 16:15:09,446 I [73] gunicorn.error - Starting gunicorn 23.0.0\n",
      "2025-04-06 16:15:09,447 I [73] gunicorn.error - Listening at: http://0.0.0.0:31311 (73)\n",
      "2025-04-06 16:15:09,447 I [73] gunicorn.error - Using worker: sync\n",
      "2025-04-06 16:15:09,450 I [138] gunicorn.error - Booting worker with pid: 138\n",
      "\n",
      "Azure ML Inferencing HTTP server v1.3.4\n",
      "\n",
      "\n",
      "Server Settings\n",
      "---------------\n",
      "Entry Script Name: /var/azureml-app/score.py\n",
      "Model Directory: /var/azureml-app/azureml-models\n",
      "Config File: None\n",
      "Worker Count: 1\n",
      "Worker Timeout (seconds): 300\n",
      "Server Port: 31311\n",
      "Health Port: 31311\n",
      "Application Insights Enabled: false\n",
      "Application Insights Key: None\n",
      "Inferencing HTTP server version: azmlinfsrv/1.3.4\n",
      "CORS for the specified origins: None\n",
      "Create dedicated endpoint for health: None\n",
      "\n",
      "\n",
      "Server Routes\n",
      "---------------\n",
      "Liveness Probe: GET   127.0.0.1:31311/\n",
      "Score:          POST  127.0.0.1:31311/score\n",
      "\n",
      "2025-04-06 16:15:09,670 W [138] azmlinfsrv - Found extra keys in the config file that are not supported by the server.\n",
      "Extra keys = ['AZUREML_ENTRY_SCRIPT', 'SERVICE_NAME', 'WORKSPACE_NAME', 'SCORING_TIMEOUT_MS', 'AZUREML_MODEL_DIR', 'HOSTNAME']\n",
      "2025-04-06 16:15:10,211 I [138] azmlinfsrv - AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\n",
      "Initializing logger\n",
      "2025-04-06 16:15:10,215 I [138] azmlinfsrv - Starting up app insights client\n",
      "2025-04-06 16:15:14,629 I [138] azmlinfsrv.user_script - Found user script at /var/azureml-app/score.py\n",
      "2025-04-06 16:15:14,629 I [138] azmlinfsrv.user_script - run() is not decorated. Server will invoke it with the input in JSON string.\n",
      "2025-04-06 16:15:14,629 I [138] azmlinfsrv.user_script - Invoking user's init function\n",
      "2025-04-06 16:15:15,386 I [138] azmlinfsrv.user_script - Users's init has completed successfully\n",
      "2025-04-06 16:15:15,387 I [138] azmlinfsrv.swagger - Swaggers are prepared for the following versions: [2, 3, 3.1].\n",
      "2025-04-06 16:15:15,387 I [138] azmlinfsrv - Scoring timeout is set to 60000\n",
      "2025-04-06 16:15:15,387 I [138] azmlinfsrv - Worker with pid 138 ready for serving traffic\n",
      "2025-04-06 16:15:17,659 W [138] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2025-04-06 16:15:17,660 I [138] gunicorn.access - 127.0.0.1 - - [06/Apr/2025:16:15:17 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n",
      "2025-04-06 16:15:17,665 W [138] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2025-04-06 16:15:17,665 I [138] azmlinfsrv - GET /swagger.json 200 0.433ms 2218\n",
      "2025-04-06 16:15:17,666 I [138] gunicorn.access - 127.0.0.1 - - [06/Apr/2025:16:15:17 +0000] \"GET /swagger.json HTTP/1.0\" 200 2218 \"-\" \"Go-http-client/1.1\"\n",
      "2025-04-06 16:15:24,184 W [138] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2025-04-06 16:15:24,185 I [138] gunicorn.access - 127.0.0.1 - - [06/Apr/2025:16:15:24 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n",
      "2025-04-06 16:15:24,187 W [138] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2025-04-06 16:15:24,188 I [138] azmlinfsrv - GET /swagger.json 200 0.773ms 2218\n",
      "2025-04-06 16:15:24,190 I [138] gunicorn.access - 127.0.0.1 - - [06/Apr/2025:16:15:24 +0000] \"GET /swagger.json HTTP/1.0\" 200 2218 \"-\" \"Go-http-client/1.1\"\n",
      "2025-04-06 16:16:27,296 W [138] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2025-04-06 16:16:27,297 I [138] gunicorn.access - 127.0.0.1 - - [06/Apr/2025:16:16:27 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n",
      "2025-04-06 16:16:27,301 W [138] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2025-04-06 16:16:27,301 I [138] azmlinfsrv - GET /swagger.json 200 0.460ms 2218\n",
      "2025-04-06 16:16:27,302 I [138] gunicorn.access - 127.0.0.1 - - [06/Apr/2025:16:16:27 +0000] \"GET /swagger.json HTTP/1.0\" 200 2218 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: [385.9725646972656, 385.8465270996094]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Select a sample (first one for testing)\n",
    "\n",
    "sample_input = [[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        [0.5, 0.4, 0.3, 0.2, 0.1]]\n",
    "\n",
    "# Define the input JSON payload\n",
    "payload = json.dumps({\"data\": sample_input})\n",
    "\n",
    "# Get the deployment endpoint\n",
    "scoring_uri = service.scoring_uri\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# Send request to the deployed model\n",
    "response = requests.post(scoring_uri, data=payload, headers=headers)\n",
    "\n",
    "# Print response\n",
    "print(\"Response:\", response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
