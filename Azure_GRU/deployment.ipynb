{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "env = Environment(name=\"azure_pytorch_env\")\n",
    "env.python.conda_dependencies.add_pip_package(\"torch==2.1.0\")\n",
    "env.python.conda_dependencies.add_pip_package(\"numpy\")\n",
    "env.python.conda_dependencies.add_pip_package(\"scikit-learn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n",
      "/tmp/ipykernel_26845/117621796.py:23: FutureWarning: azureml.core.model:\n",
      "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
      "please refer to respective documentations \n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
      "For more information on migration, see https://aka.ms/acimoemigration \n",
      "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
      "  service = Model.deploy(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2025-04-08 19:55:57+05:45 Registering the environment.\n",
      "2025-04-08 19:56:02+05:45 Use the existing image.\n",
      "2025-04-08 19:56:03+05:45 Generating deployment configuration.\n",
      "2025-04-08 19:56:05+05:45 Submitting deployment to compute..\n",
      "2025-04-08 19:56:13+05:45 Checking the status of deployment pytorch-nnnn-gru-scalar..\n",
      "2025-04-08 19:59:33+05:45 Checking the status of inference endpoint pytorch-nnnn-gru-scalar.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Deployment successful! Scoring URI: http://052b8af2-5fc7-4af2-adc6-4e7dff223ca8.eastus2.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Model\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "# Connect to Azure ML Workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Load registered model and scaler\n",
    "model = Model(ws, \"pytorch_gru\")\n",
    "scaler = Model(ws, \"scaler\")\n",
    "\n",
    "\n",
    "# Define inference configuration\n",
    "inference_config = InferenceConfig(\n",
    "    entry_script=\"score.py\",\n",
    "    environment=env\n",
    ")\n",
    "\n",
    "# Define deployment configuration (ACI)\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "# Deploy both the model and scaler\n",
    "service = Model.deploy(\n",
    "    workspace=ws,\n",
    "    name=\"pytorch-nnnn-gru-scalar\",\n",
    "    models=[model, scaler],  # <-- Include both\n",
    "    inference_config=inference_config,\n",
    "    deployment_config=deployment_config\n",
    ")\n",
    "\n",
    "service.wait_for_deployment(show_output=True)\n",
    "\n",
    "# Print Scoring URI\n",
    "print(f\"Deployment successful! Scoring URI: {service.scoring_uri}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: [74.09484100341797, 673.948974609375]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Select a sample (first one for testing)\n",
    "\n",
    "sample_input = [[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        [700, 705, 708, 715, 719]]\n",
    "\n",
    "# Define the input JSON payload\n",
    "payload = json.dumps({\"data\": sample_input})\n",
    "\n",
    "# Get the deployment endpoint\n",
    "scoring_uri = service.scoring_uri\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# Send request to the deployed model\n",
    "response = requests.post(scoring_uri, data=payload, headers=headers)\n",
    "\n",
    "# Print response\n",
    "print(\"Response:\", response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
